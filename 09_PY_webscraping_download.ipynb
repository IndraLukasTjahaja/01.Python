{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Go through OJK page that contains Statistik Perbankan Indonesia page\n",
    "# Go through all links of SPI that available in the main SPI page (usually will be the last 10 months)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ojk.go.id/id/kanal/perbankan/data-dan-statistik/statistik-perbankan-indonesia/default.aspx'\n",
    "root = 'https://www.ojk.go.id/'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "all_hrefs = soup.find_all('a')\n",
    "all_links = [link.get('href') for link in all_hrefs]\n",
    "\n",
    "SPI_links = [dl for dl in all_links if dl and 'Statistik-Perbankan-Indonesia---' in dl]\n",
    "\n",
    "download_folder = 'output/OJK_SPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through each SPI links, then download the zip files and unzip them\n",
    "# unzip the files \n",
    "\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n",
    "\n",
    "tries = 0\n",
    "for SPI_link in SPI_links:\n",
    "    url = root + SPI_link\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    all_hrefs = soup.find_all('a')\n",
    "    all_links = [link.get('href') for link in all_hrefs]\n",
    "    zip_files = [dl for dl in all_links if dl and '.zip' in dl]\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        full_url = root + zip_file\n",
    "        zip_filename = os.path.basename(zip_file)\n",
    "        dl_path = os.path.join(download_folder, zip_filename)\n",
    "        if os.path.exists(dl_path):\n",
    "            # you have already downloaded this file, so skip it\n",
    "            continue\n",
    "\n",
    "        while tries < 3:\n",
    "            r = requests.get(full_url)\n",
    "            dl_path = os.path.join(download_folder, zip_filename)\n",
    "            with open(dl_path, 'wb') as z_file:\n",
    "                z_file.write(r.content)\n",
    "\n",
    "            # unzip the file\n",
    "            # use this if want to extract the file to subfolder based on file name: extract_dir = os.path.splitext(os.path.basename(zip_file))[0]\n",
    "            try:\n",
    "                z = zipfile.ZipFile(dl_path)\n",
    "                z.extractall(os.path.join(download_folder))\n",
    "                break\n",
    "            except zipfile.BadZipfile:\n",
    "                # the file didn't download correctly, so try again\n",
    "                # this is also a good place to log the error\n",
    "                pass\n",
    "            tries += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete all zip files\n",
    "\n",
    "download_content = os.listdir( download_folder )\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".zip\"):\n",
    "        os.remove( os.path.join( download_content, item ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the latest file\n",
    "\n",
    "# Calling DataFrame constructor on list \n",
    "df_download = pd.DataFrame(download_content, columns =['File_Name']) \n",
    "df_download['Name'] = df_download['File_Name'].str.replace('.xlsx', '')\n",
    "\n",
    "df_download[\"Month\"] = (df_download[\"Name\"].str.split(\" \", n = 3, expand = True))[1] \n",
    "df_download[\"Year\"] = (df_download[\"Name\"].str.split(\" \", n = 3, expand = True))[2] \n",
    "\n",
    "conditions = [\n",
    "              (df_download['Month'] == 'Januari'),\n",
    "              (df_download['Month'] == 'Februari'),\n",
    "              (df_download['Month'] == 'Maret'),\n",
    "              (df_download['Month'] == 'April'),\n",
    "              (df_download['Month'] == 'Mei'),\n",
    "              (df_download['Month'] == 'Juni'),\n",
    "              (df_download['Month'] == 'Juli'),\n",
    "              (df_download['Month'] == 'Agustus'),\n",
    "              (df_download['Month'] == 'September'),\n",
    "              (df_download['Month'] == 'Oktober'),\n",
    "              (df_download['Month'] == 'November'),\n",
    "              (df_download['Month'] == 'Desember')\n",
    "             ]\n",
    "choices = [\n",
    "           '1',\n",
    "           '2',\n",
    "           '3',\n",
    "           '4',\n",
    "           '5',\n",
    "           '6',\n",
    "           '7',\n",
    "           '8',\n",
    "           '9',\n",
    "           '10',\n",
    "           '11',\n",
    "           '12'\n",
    "           ]\n",
    "df_download['Month_str'] = np.select(conditions,choices, default=np.nan) #nan is default value\"\n",
    "\n",
    "df_download['Report_Date'] = pd.to_datetime(df_download['Year'].astype(str)+\"-\"+df_download['Month_str'].astype(str), format='%Y-%m')\n",
    "\n",
    "max_date = max(df_download['Report_Date'])\n",
    "max_report = df_download[df_download['Report_Date'] == max_date]\n",
    "final_report = max_report.iloc[0]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kredit per Lok. Dati I_3.17.a.\n",
    "\n"
   ]
  }
 ]
}